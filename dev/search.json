[{"path":"https://r-lib.github.io/nanoparquet/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Gábor Csárdi. Author, maintainer. Hannes Mühleisen. Author, copyright holder. Google Inc.. Copyright holder. Apache Software Foundation. Copyright holder. . Copyright holder. RAD Game Tools. Copyright holder. Valve Software. Copyright holder. Tenacious Software LLC. Copyright holder. Facebook, Inc.. Copyright holder.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Csárdi G, Mühleisen H (2024). nanoparquet: Read Write 'Parquet' Files. R package version 0.3.1.9000, https://r-lib.github.io/nanoparquet/, https://github.com/r-lib/nanoparquet.","code":"@Manual{,   title = {nanoparquet: Read and Write 'Parquet' Files},   author = {Gábor Csárdi and Hannes Mühleisen},   year = {2024},   note = {R package version 0.3.1.9000,     https://r-lib.github.io/nanoparquet/},   url = {https://github.com/r-lib/nanoparquet}, }"},{"path":"https://r-lib.github.io/nanoparquet/dev/index.html","id":"nanoparquet","dir":"","previous_headings":"","what":"Read and Write Parquet Files","title":"Read and Write Parquet Files","text":"nanoparquet reader writer common subset Parquet files.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/index.html","id":"features","dir":"","previous_headings":"","what":"Features:","title":"Read and Write Parquet Files","text":"Read write flat (.e. non-nested) Parquet files. Can read Parquet data types. Can write many R data types, including factors temporal types Parquet. Completely dependency free. Supports Snappy, Gzip Zstd compression.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/index.html","id":"limitations","dir":"","previous_headings":"","what":"Limitations:","title":"Read and Write Parquet Files","text":"Nested Parquet types supported. Parquet logical types supported: FLOAT16, INTERVAL, UNKNOWN. Snappy, Gzip Zstd compression supported. Encryption supported. Reading files URLs supported. single-threaded fully optimized, nanoparquet probably suited well large data sets. fine couple gigabytes. Reading writing ~250MB file 32 million rows 14 columns takes 10-15 seconds M2 MacBook Pro. larger files, use Apache Arrow DuckDB.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Read and Write Parquet Files","text":"Install R package CRAN:","code":"install.packages(\"nanoparquet\")"},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/index.html","id":"read","dir":"","previous_headings":"Usage","what":"Read","title":"Read and Write Parquet Files","text":"Call read_parquet() read Parquet file: see columns Parquet file types mapped R types read_parquet(), call parquet_column_types() first: Folders similar-structured Parquet files (e.g. produced Spark) can read like :","code":"df <- nanoparquet::read_parquet(\"example.parquet\") nanoparquet::parquet_column_types(\"example.parquet\") df <- data.table::rbindlist(lapply(   Sys.glob(\"some-folder/part-*.parquet\"),   nanoparquet::read_parquet ))"},{"path":"https://r-lib.github.io/nanoparquet/dev/index.html","id":"write","dir":"","previous_headings":"Usage","what":"Write","title":"Read and Write Parquet Files","text":"Call write_parquet() write data frame Parquet file: see columns data frame mapped Parquet types write_parquet(), call parquet_column_types() first:","code":"nanoparquet::write_parquet(mtcars, \"mtcars.parquet\") nanoparquet::parquet_column_types(mtcars)"},{"path":"https://r-lib.github.io/nanoparquet/dev/index.html","id":"inspect","dir":"","previous_headings":"Usage","what":"Inspect","title":"Read and Write Parquet Files","text":"Call parquet_info(), parquet_column_types(), parquet_schema() parquet_metadata() see various kinds metadata Parquet file: parquet_info() shows basic summary file. parquet_column_types() shows leaf columns, ones read_parquet() reads R. parquet_schema() shows columns, including non-leaf columns. parquet_metadata() shows complete metadata information: file meta data, schema, row groups column chunks file. find file supported isn’t, please open issue link file.","code":"nanoparquet::parquet_info(\"mtcars.parquet\") nanoparquet::parquet_column_types(\"mtcars.parquet\") nanoparquet::parquet_schema(\"mtcars.parquet\") nanoparquet::parquet_metadata(\"mtcars.parquet\")"},{"path":"https://r-lib.github.io/nanoparquet/dev/index.html","id":"options","dir":"","previous_headings":"","what":"Options","title":"Read and Write Parquet Files","text":"See also ?parquet_options(). nanoparquet.class: extra class add data frames returned read_parquet(). defined, default \"tbl\", changes data frame printed pillar package loaded. nanoparquet.use_arrow_metadata: unless set FALSE, read_parquet() make use Arrow metadata Parquet file. Currently used detect factor columns. nanoparquet.write_arrow_metadata: unless set FALSE, write_parquet() add Arrow metadata Parquet file. helps preserving classes columns, e.g. factors read back factors, nanoparquet Arrow.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Read and Write Parquet Files","text":"MIT","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-package.html","id":null,"dir":"Reference","previous_headings":"","what":"nanoparquet: Read and Write 'Parquet' Files — nanoparquet-package","title":"nanoparquet: Read and Write 'Parquet' Files — nanoparquet-package","text":"Self-sufficient reader writer flat 'Parquet' files. Can read 'Parquet' data types. Can write many 'R' data types, including factors temporal types. See docs limitations.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"nanoparquet: Read and Write 'Parquet' Files — nanoparquet-package","text":"nanoparquet reader writer common subset Parquet files.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-package.html","id":"features-","dir":"Reference","previous_headings":"","what":"Features:","title":"nanoparquet: Read and Write 'Parquet' Files — nanoparquet-package","text":"Read write flat (.e. non-nested) Parquet files. Can read Parquet data types. Can write many R data types, including factors temporal types Parquet. Completely dependency free. Supports Snappy, Gzip Zstd compression.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-package.html","id":"limitations-","dir":"Reference","previous_headings":"","what":"Limitations:","title":"nanoparquet: Read and Write 'Parquet' Files — nanoparquet-package","text":"Nested Parquet types supported. Parquet logical types supported: FLOAT16, INTERVAL, UNKNOWN. Snappy, Gzip Zstd compression supported. Encryption supported. Reading files URLs supported. single-threaded fully optimized, nanoparquet probably suited well large data sets. fine couple gigabytes. Reading writing ~250MB file 32 million rows 14 columns takes 10-15 seconds M2 MacBook Pro. larger files, use Apache Arrow DuckDB.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-package.html","id":"installation","dir":"Reference","previous_headings":"","what":"Installation","title":"nanoparquet: Read and Write 'Parquet' Files — nanoparquet-package","text":"Install R package CRAN:","code":"install.packages(\"nanoparquet\")"},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-package.html","id":"read","dir":"Reference","previous_headings":"","what":"Read","title":"nanoparquet: Read and Write 'Parquet' Files — nanoparquet-package","text":"Call read_parquet() read Parquet file:   see columns Parquet file types mapped R types read_parquet(), call parquet_column_types() first:   Folders similar-structured Parquet files (e.g. produced Spark) can read like :","code":"df <- nanoparquet::read_parquet(\"example.parquet\") nanoparquet::parquet_column_types(\"example.parquet\") df <- data.table::rbindlist(lapply(   Sys.glob(\"some-folder/part-*.parquet\"),   nanoparquet::read_parquet ))"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-package.html","id":"write","dir":"Reference","previous_headings":"","what":"Write","title":"nanoparquet: Read and Write 'Parquet' Files — nanoparquet-package","text":"Call write_parquet() write data frame Parquet file:   see columns data frame mapped Parquet types write_parquet(), call parquet_column_types() first:","code":"nanoparquet::write_parquet(mtcars, \"mtcars.parquet\") nanoparquet::parquet_column_types(mtcars)"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-package.html","id":"inspect","dir":"Reference","previous_headings":"","what":"Inspect","title":"nanoparquet: Read and Write 'Parquet' Files — nanoparquet-package","text":"Call parquet_info(), parquet_column_types(), parquet_schema() parquet_metadata() see various kinds metadata Parquet file: parquet_info() shows basic summary file. parquet_column_types() shows leaf columns, ones read_parquet() reads R. parquet_schema() shows columns, including non-leaf columns. parquet_metadata() shows complete metadata information: file meta data, schema, row groups column chunks file.   find file supported , please open issue link file.","code":"nanoparquet::parquet_info(\"mtcars.parquet\") nanoparquet::parquet_column_types(\"mtcars.parquet\") nanoparquet::parquet_schema(\"mtcars.parquet\") nanoparquet::parquet_metadata(\"mtcars.parquet\")"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-package.html","id":"options","dir":"Reference","previous_headings":"","what":"Options","title":"nanoparquet: Read and Write 'Parquet' Files — nanoparquet-package","text":"See also ?parquet_options(). nanoparquet.class: extra class add data frames returned read_parquet(). defined, default \"tbl\", changes data frame printed pillar package loaded. nanoparquet.use_arrow_metadata: unless set FALSE, read_parquet() make use Arrow metadata Parquet file. Currently used detect factor columns. nanoparquet.write_arrow_metadata: unless set FALSE, write_parquet() add Arrow metadata Parquet file. helps preserving classes columns, e.g. factors read back factors, nanoparquet Arrow.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-package.html","id":"license","dir":"Reference","previous_headings":"","what":"License","title":"nanoparquet: Read and Write 'Parquet' Files — nanoparquet-package","text":"MIT","code":""},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"nanoparquet: Read and Write 'Parquet' Files — nanoparquet-package","text":"Maintainer: Gábor Csárdi csardi.gabor@gmail.com Authors: Hannes Mühleisen (ORCID) [copyright holder] contributors: Google Inc. [copyright holder] Apache Software Foundation [copyright holder] Posit Software, PBC [copyright holder] RAD Game Tools [copyright holder] Valve Software [copyright holder] Tenacious Software LLC [copyright holder] Facebook, Inc. [copyright holder]","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-types.html","id":null,"dir":"Reference","previous_headings":"","what":"nanoparquet's type maps — nanoparquet-types","title":"nanoparquet's type maps — nanoparquet-types","text":"nanoparquet maps R types Parquet types.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-types.html","id":"r-s-data-types","dir":"Reference","previous_headings":"","what":"R's data types","title":"nanoparquet's type maps — nanoparquet-types","text":"writing data frame, nanoparquet maps R's data types Parquet logical types. mapping performed. rules likely change nanoparquet reaches version 1.0.0. Factors (.e. vectors inherit factor class) converted character vectors using .character(), written STRSXP (character vector) type. fact column factor stored Arrow metadata (see ), unless nanoparquet.write_arrow_metadata option set FALSE. Dates (.e. Date class) written DATE logical type, INT32 type internally. hms objects (hms package) written TIME(true, MILLIS). logical type, internally INT32 Parquet type. Sub-milliseconds precision lost. POSIXct objects written TIMESTAMP(true, MICROS) logical type, internally INT64 Parquet type. Sub-microsecond precision lost. difftime objects (hms objects, see ), written INT64 Parquet type, noting Arrow metadata (see ) column type Duration NANOSECONDS unit. Integer vectors (INTSXP) written INT(32, true) logical type, corresponds INT32 type. Real vectors (REALSXP) written DOUBLE type. Character vectors (STRSXP) written STRING logical type, BYTE_ARRAY type. always converted UTF-8 writing. Logical vectors (LGLSXP) written BOOLEAN type. vectors error currently. can use parquet_column_types() data frame map R data types Parquet data types.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-types.html","id":"parquet-s-data-types","dir":"Reference","previous_headings":"","what":"Parquet's data types","title":"nanoparquet's type maps — nanoparquet-types","text":"reading Parquet file nanoparquet also relies logical types Arrow metadata (present, see ) addition low level data types. exact rules . rules likely change nanoparquet reaches version 1.0.0. BOOLEAN type read logical vector (LGLSXP). STRING logical type UTF8 converted type read character vector UTF-8 encoding. DATE logical type DATE converted type read Date R object. TIME logical type TIME_MILLIS TIME_MICROS converted types read hms object, see hms package. TIMESTAMP logical type TIMESTAMP_MILLIS TIMESTAMP_MICROS converted types read POSIXct objects. logical type UTC flag set, time zone POSIXct object set UTC. INT32 read integer vector (INTSXP). INT64, DOUBLE FLOAT read real vectors (REALSXP). INT96 read POSIXct read vector tzone attribute set \"UTC\". old convention store time stamps INT96 objects. DECIMAL converted type (FIXED_LEN_BYTE_ARRAY BYTE_ARRAY type) read real vector (REALSXP), potentially losing precision. ENUM logical type read character vector. UUID logical type read character vector uses 00112233-4455-6677-8899-aabbccddeeff form. BYTE_ARRAY read factor object file written Arrow original data type column factor. (See 'Arrow metadata .) Otherwise BYTE_ARRAY read list raw vectors, missing values denoted NULL. logical converted types read annotated low level types: INT(8, true), INT(16, true) INT(32, true) read integer vectors INT32 internally Parquet. INT(64, true) read real vector (REALSXP). Unsigned integer types INT(8, false), INT(16, false) INT(32, false) read integer vectors (INTSXP). Large positive values may overflow negative values, known issue fix. INT(64, false) read real vector (REALSXP). Large positive values may overflow negative values, known issue fix. FLOAT16 fixed length byte array, nanoparquet reads list raw vectors. Missing values denoted NULL. INTERVAL fixed length byte array, nanoparquet reads list raw vectors. Missing values denoted NULL. JSON BSON read character vectors (STRSXP). types yet supported: Nested types (LIST, MAP) supported. UNKNOWN logical type supported. can use parquet_column_types() function see R read columns Parquet file. Look r_type column.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/nanoparquet-types.html","id":"the-arrow-metadata","dir":"Reference","previous_headings":"","what":"The Arrow metadata","title":"nanoparquet's type maps — nanoparquet-types","text":"Apache Arrow (.e. arrow R package) adds additional metadata Parquet files writing arrow::write_parquet(). , reading file arrow::read_parquet(), uses metadata recreate Arrow R data types writing. nanoparquet::write_parquet() also adds Arrow metadata Parquet files, unless nanoparquet.write_arrow_metadata option set FALSE. Similarly, nanoparquet::read_parquet() uses Arrow metadata Parquet file (present), unless nanoparquet.use_arrow_metadata option set FALSE. Arrow metadata stored file level key-value metadata, key ARROW:schema. Currently nanoparquet uses Arrow metadata two things: uses detect factors. Without Arrow metadata factors read string vectors. uses detect difftime objects. Without arrow metadata read INT64 columns, containing time difference nanoseconds.","code":""},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_column_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Map between R and Parquet data types — parquet_column_types","title":"Map between R and Parquet data types — parquet_column_types","text":"function works two ways. can map R types data frame Parquet types, see write_parquet() write data frame. can also map types Parquet file R types, see read_parquet() read file R.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_column_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map between R and Parquet data types — parquet_column_types","text":"","code":"parquet_column_types(x, options = parquet_options())"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_column_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map between R and Parquet data types — parquet_column_types","text":"x Path Parquet file, data frame. options Nanoparquet options, see parquet_options().","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_column_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map between R and Parquet data types — parquet_column_types","text":"Data frame columns: file_name: file name. name: column name. type: (low level) Parquet data type. r_type: R type corresponds Parquet type. Might NA read_parquet() read column. See nanoparquet-types type mapping rules. repetition_type: whether column REQUIRED (NA) OPTIONAL (may NA). REPEATED columns currently supported nanoparquet. logical_type: Parquet logical type list column. element least entry called type, potentially additional entries, e.g. bit_width, is_signed, etc.","code":""},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Short summary of a Parquet file — parquet_info","title":"Short summary of a Parquet file — parquet_info","text":"Short summary Parquet file","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Short summary of a Parquet file — parquet_info","text":"","code":"parquet_info(file)"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Short summary of a Parquet file — parquet_info","text":"file Path Parquet file.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Short summary of a Parquet file — parquet_info","text":"Data frame columns: file_name: file name. num_cols: number (leaf) columns. num_rows: number rows. num_row_groups: number row groups. file_size: file size bytes. parquet_version: Parquet version. created_by: string scalar, usually name software created file. NA available.","code":""},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Read the metadata of a Parquet file — parquet_metadata","title":"Read the metadata of a Parquet file — parquet_metadata","text":"function work files, even read_parquet() unable read , unsupported schema, encoding, compression reason.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read the metadata of a Parquet file — parquet_metadata","text":"","code":"parquet_metadata(file)"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read the metadata of a Parquet file — parquet_metadata","text":"file Path Parquet file.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read the metadata of a Parquet file — parquet_metadata","text":"named list entries: file_meta_data: data frame file meta data: file_name: file name. version: Parquet version, integer. num_rows: total number rows. key_value_metadata: list column data frames two character columns called key value. key-value metadata file. Arrow stores schema . created_by: string scalar, usually name software created file. schema: data frame, schema file. one row node (inner node leaf node). flat files means one root node (inner node), always first one, one row \"real\" column. nested schemas, rows depth-first search order. important columns : file_name: file name. name: column name. type: data type. One low level data types. type_length: length fixed length byte arrays. repettion_type: character, one REQUIRED, OPTIONAL REPEATED. logical_type: list column, logical types columns. element least entry called type, potentially additional entries, e.g. bit_width, is_signed, etc. num_children: number child nodes. non-negative integer root node, NA leaf node. $row_groups: data frame, information row groups. $column_chunks: data frame, information column chunks, across row groups. important columns: file_name: file name. row_group: row group chunk belongs . column: leaf column chunks belongs . order $schema, leaf columns (.e. columns NA children) counted. file_path: file chunk stored . NA means file. file_offset: column chunk begins file. type: low level parquet data type. encodings: encodings used store chunk. list column character vectors encoding names. Current possible encodings: \"PLAIN\", \"GROUP_VAR_INT\", \"PLAIN_DICTIONARY\", \"RLE\", \"BIT_PACKED\", \"DELTA_BINARY_PACKED\", \"DELTA_LENGTH_BYTE_ARRAY\", \"DELTA_BYTE_ARRAY\", \"RLE_DICTIONARY\", \"BYTE_STREAM_SPLIT\". path_in_scema: list column character vectors. simply path root node. simply column name flat schemas. codec: compression codec used column chunk. Possible values : \"UNCOMPRESSED\", \"SNAPPY\", \"GZIP\", \"LZO\", \"BROTLI\", \"LZ4\", \"ZSTD\". num_values: number values column chunk. total_uncompressed_size: total uncompressed size bytes. total_compressed_size: total compressed size bytes. data_page_offset: absolute position first data page column chunk file. index_page_offset: absolute position first index page column chunk file, NA index pages. dictionary_page_offset: absolute position first dictionary page column chunk file, NA dictionary pages.","code":""},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read the metadata of a Parquet file — parquet_metadata","text":"","code":"file_name <- system.file(\"extdata/userdata1.parquet\", package = \"nanoparquet\") nanoparquet::parquet_metadata(file_name) #> $file_meta_data #> # A data frame: 1 × 5 #>   file_name                 version num_rows key_value_metadata created_by #>   <chr>                       <int>    <dbl> <I<list>>          <chr>      #> 1 /home/runner/work/_temp/…       1     1000 <tbl [1 × 2]>      https://g… #>  #> $schema #> # A data frame: 14 × 11 #>    file_name        name  type  type_length repetition_type converted_type #>    <chr>            <chr> <chr>       <int> <chr>           <chr>          #>  1 /home/runner/wo… sche… NA             NA NA              NA             #>  2 /home/runner/wo… regi… INT64          NA REQUIRED        TIMESTAMP_MIC… #>  3 /home/runner/wo… id    INT32          NA REQUIRED        INT_32         #>  4 /home/runner/wo… firs… BYTE…          NA OPTIONAL        UTF8           #>  5 /home/runner/wo… last… BYTE…          NA REQUIRED        UTF8           #>  6 /home/runner/wo… email BYTE…          NA OPTIONAL        UTF8           #>  7 /home/runner/wo… gend… BYTE…          NA OPTIONAL        UTF8           #>  8 /home/runner/wo… ip_a… BYTE…          NA REQUIRED        UTF8           #>  9 /home/runner/wo… cc    BYTE…          NA OPTIONAL        UTF8           #> 10 /home/runner/wo… coun… BYTE…          NA REQUIRED        UTF8           #> 11 /home/runner/wo… birt… INT32          NA OPTIONAL        DATE           #> 12 /home/runner/wo… sala… DOUB…          NA OPTIONAL        NA             #> 13 /home/runner/wo… title BYTE…          NA OPTIONAL        UTF8           #> 14 /home/runner/wo… comm… BYTE…          NA OPTIONAL        UTF8           #> # ℹ 5 more variables: logical_type <I<list>>, num_children <int>, #> #   scale <int>, precision <int>, field_id <int> #>  #> $row_groups #> # A data frame: 1 × 7 #>   file_name                        id total_byte_size num_rows file_offset #>   <chr>                         <int>           <dbl>    <dbl>       <dbl> #> 1 /home/runner/work/_temp/Libr…     0           71427     1000          NA #> # ℹ 2 more variables: total_compressed_size <dbl>, ordinal <int> #>  #> $column_chunks #> # A data frame: 13 × 19 #>    file_name    row_group column file_path file_offset offset_index_offset #>    <chr>            <int>  <int> <chr>           <dbl>               <dbl> #>  1 /home/runne…         0      0 NA                  4                  NA #>  2 /home/runne…         0      1 NA               6741                  NA #>  3 /home/runne…         0      2 NA              12259                  NA #>  4 /home/runne…         0      3 NA              15211                  NA #>  5 /home/runne…         0      4 NA              16239                  NA #>  6 /home/runne…         0      5 NA              31759                  NA #>  7 /home/runne…         0      6 NA              32031                  NA #>  8 /home/runne…         0      7 NA              42952                  NA #>  9 /home/runne…         0      8 NA              55009                  NA #> 10 /home/runne…         0      9 NA              55925                  NA #> 11 /home/runne…         0     10 NA              59312                  NA #> 12 /home/runne…         0     11 NA              67026                  NA #> 13 /home/runne…         0     12 NA              71089                  NA #> # ℹ 13 more variables: offset_index_length <int>, #> #   column_index_offset <dbl>, column_index_length <int>, type <chr>, #> #   encodings <I<list>>, path_in_schema <I<list>>, codec <chr>, #> #   num_values <dbl>, total_uncompressed_size <dbl>, #> #   total_compressed_size <dbl>, data_page_offset <dbl>, #> #   index_page_offset <dbl>, dictionary_page_offset <dbl> #>"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Nanoparquet options — parquet_options","title":"Nanoparquet options — parquet_options","text":"Create list nanoparquet options.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nanoparquet options — parquet_options","text":"","code":"parquet_options(   class = getOption(\"nanoparquet.class\", \"tbl\"),   use_arrow_metadata = getOption(\"nanoparquet.use_arrow_metadata\", TRUE),   write_arrow_metadata = getOption(\"nanoparquet.write_arrow_metadata\", TRUE) )"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nanoparquet options — parquet_options","text":"class extra class classes add data frames created read_parquet(). default nanoparquet adds \"tbl\" class, data frames printed differently pillar package loaded. use_arrow_metadata TRUE FALSE. TRUE, read_parquet() parquet_column_types() make use Apache Arrow metadata assign R classes Parquet columns. currently used detect factor columns, detect \"difftime\" columns. option FALSE: \"factor\" columns read character vectors. \"difftime\" columns read real numbers, meaning one seconds, milliseconds, microseconds nanoseconds. Impossible tell without using Arrow metadata. write_arrow_metadata Whether add Apache Arrow types metadata file write_parquet().","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nanoparquet options — parquet_options","text":"List nanoparquet options.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nanoparquet options — parquet_options","text":"","code":"if (FALSE) { # the effect of using Arrow metadata tmp <- tempfile(fileext = \".parquet\") d <- data.frame(   fct = as.factor(\"a\"),   dft = as.difftime(10, units = \"secs\") ) write_parquet(d, tmp) read_parquet(tmp, options = parquet_options(use_arrow_metadata = TRUE)) read_parquet(tmp, options = parquet_options(use_arrow_metadata = FALSE)) }"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_pages.html","id":null,"dir":"Reference","previous_headings":"","what":"Metadata of all pages of a Parquet file — parquet_pages","title":"Metadata of all pages of a Parquet file — parquet_pages","text":"Metadata pages Parquet file","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_pages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Metadata of all pages of a Parquet file — parquet_pages","text":"","code":"parquet_pages(file)"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_pages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Metadata of all pages of a Parquet file — parquet_pages","text":"file Path Parquet file.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_pages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Metadata of all pages of a Parquet file — parquet_pages","text":"Data frame columns: file_name: file name. row_group: id row group page belongs , integer 0 number row groups minus one. column: id column. integer number leaf columns minus one. Note leaf columns considered, non-leaf columns pages. page_type: DATA_PAGE, INDEX_PAGE, DICTIONARY_PAGE DATA_PAGE_V2. page_header_offset: offset data page (header) file. uncompressed_page_size: include page header, per Parquet spec. compressed_page_size: without page header. crc: integer, checksum, present file, can NA. num_values: number data values page, include NULL (NA R) values. encoding: encoding page, current possible encodings: \"PLAIN\", \"GROUP_VAR_INT\", \"PLAIN_DICTIONARY\", \"RLE\", \"BIT_PACKED\", \"DELTA_BINARY_PACKED\", \"DELTA_LENGTH_BYTE_ARRAY\", \"DELTA_BYTE_ARRAY\", \"RLE_DICTIONARY\", \"BYTE_STREAM_SPLIT\". definition_level_encoding: encoding definition levels, see encoding possible values. can missing V2 data pages, always RLE encoded. repetition_level_encoding: encoding repetition levels, see encoding possible values. can missing V2 data pages, always RLE encoded. data_offset: offset actual data file. page_header_length: size page header, bytes.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_pages.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Metadata of all pages of a Parquet file — parquet_pages","text":"Reading page headers might slow large files, especially file many small pages.","code":""},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_pages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Metadata of all pages of a Parquet file — parquet_pages","text":"","code":"file_name <- system.file(\"extdata/userdata1.parquet\", package = \"nanoparquet\") nanoparquet:::parquet_pages(file_name) #> # A data frame: 19 × 14 #>    file_name                 row_group column page_type page_header_offset #>    <chr>                         <int>  <int> <chr>                  <dbl> #>  1 /home/runner/work/_temp/…         0      0 DATA_PAGE                  4 #>  2 /home/runner/work/_temp/…         0      1 DATA_PAGE               6741 #>  3 /home/runner/work/_temp/…         0      2 DICTIONA…              10766 #>  4 /home/runner/work/_temp/…         0      2 DATA_PAGE              12259 #>  5 /home/runner/work/_temp/…         0      3 DICTIONA…              13334 #>  6 /home/runner/work/_temp/…         0      3 DATA_PAGE              15211 #>  7 /home/runner/work/_temp/…         0      4 DATA_PAGE              16239 #>  8 /home/runner/work/_temp/…         0      5 DICTIONA…              31726 #>  9 /home/runner/work/_temp/…         0      5 DATA_PAGE              31759 #> 10 /home/runner/work/_temp/…         0      6 DATA_PAGE              32031 #> 11 /home/runner/work/_temp/…         0      7 DATA_PAGE              42952 #> 12 /home/runner/work/_temp/…         0      8 DICTIONA…              53749 #> 13 /home/runner/work/_temp/…         0      8 DATA_PAGE              55009 #> 14 /home/runner/work/_temp/…         0      9 DATA_PAGE              55925 #> 15 /home/runner/work/_temp/…         0     10 DATA_PAGE              59312 #> 16 /home/runner/work/_temp/…         0     11 DICTIONA…              65063 #> 17 /home/runner/work/_temp/…         0     11 DATA_PAGE              67026 #> 18 /home/runner/work/_temp/…         0     12 DICTIONA…              68019 #> 19 /home/runner/work/_temp/…         0     12 DATA_PAGE              71089 #> # ℹ 9 more variables: uncompressed_page_size <int>, #> #   compressed_page_size <int>, crc <int>, num_values <int>, #> #   encoding <chr>, definition_level_encoding <chr>, #> #   repetition_level_encoding <chr>, data_offset <dbl>, #> #   page_header_length <int>"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Read the schema of a Parquet file — parquet_schema","title":"Read the schema of a Parquet file — parquet_schema","text":"function work files, even read_parquet() unable read , unsupported schema, encoding, compression reason.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read the schema of a Parquet file — parquet_schema","text":"","code":"parquet_schema(file)"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read the schema of a Parquet file — parquet_schema","text":"file Path Parquet file.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/parquet_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read the schema of a Parquet file — parquet_schema","text":"","code":"Data frame, the schema of the file. It has one row for each node (inner node or leaf node). For flat files this means one root node (inner node), always the first one, and then one row for each \"real\" column. For nested schemas, the rows are in depth-first search order. Most important columns are: - `file_name`: file name. - `name`: column name. - `type`: data type. One of the low level data types. - `type_length`: length for fixed length byte arrays. - `repettion_type`: character, one of `REQUIRED`, `OPTIONAL` or   `REPEATED`. - `logical_type`: a list column, the logical types of the columns.   An element has at least an entry called `type`, and potentially   additional entries, e.g. `bit_width`, `is_signed`, etc. - `num_children`: number of child nodes. Should be a non-negative   integer for the root node, and `NA` for a leaf node."},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/read_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a Parquet file into a data frame — read_parquet","title":"Read a Parquet file into a data frame — read_parquet","text":"Converts contents named Parquet file R data frame.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/read_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a Parquet file into a data frame — read_parquet","text":"","code":"read_parquet(file, options = parquet_options())"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/read_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a Parquet file into a data frame — read_parquet","text":"file Path Parquet file. options Nanoparquet options, see parquet_options().","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/read_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a Parquet file into a data frame — read_parquet","text":"data.frame file's contents.","code":""},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/read_parquet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a Parquet file into a data frame — read_parquet","text":"","code":"file_name <- system.file(\"extdata/userdata1.parquet\", package = \"nanoparquet\") parquet_df <- nanoparquet::read_parquet(file_name) print(str(parquet_df)) #> Classes ‘tbl’ and 'data.frame':\t1000 obs. of  13 variables: #>  $ registration: POSIXct, format: \"2016-02-03 07:55:29\" \"2016-02-03 17:04:03\" ... #>  $ id          : int  1 2 3 4 5 6 7 8 9 10 ... #>  $ first_name  : chr  \"Amanda\" \"Albert\" \"Evelyn\" \"Denise\" ... #>  $ last_name   : chr  \"Jordan\" \"Freeman\" \"Morgan\" \"Riley\" ... #>  $ email       : chr  \"ajordan0@com.com\" \"afreeman1@is.gd\" \"emorgan2@altervista.org\" \"driley3@gmpg.org\" ... #>  $ gender      : Factor w/ 2 levels \"Female\",\"Male\": 1 2 1 1 NA 1 2 2 2 1 ... #>  $ ip_address  : chr  \"1.197.201.2\" \"218.111.175.34\" \"7.161.136.94\" \"140.35.109.83\" ... #>  $ cc          : chr  \"6759521864920116\" NA \"6767119071901597\" \"3576031598965625\" ... #>  $ country     : chr  \"Indonesia\" \"Canada\" \"Russia\" \"China\" ... #>  $ birthdate   : Date, format: \"1971-03-08\" \"1968-01-16\" ... #>  $ salary      : num  49757 150280 144973 90263 NA ... #>  $ title       : chr  \"Internal Auditor\" \"Accountant IV\" \"Structural Engineer\" \"Senior Cost Accountant\" ... #>  $ comments    : chr  \"1E+02\" NA NA NA ... #> NULL"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/read_parquet_page.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a page from a Parquet file — read_parquet_page","title":"Read a page from a Parquet file — read_parquet_page","text":"Read page Parquet file","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/read_parquet_page.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a page from a Parquet file — read_parquet_page","text":"","code":"read_parquet_page(file, offset)"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/read_parquet_page.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a page from a Parquet file — read_parquet_page","text":"file Path Parquet file. offset Integer offset start page file. See parquet_pages() list pages offsets.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/read_parquet_page.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a page from a Parquet file — read_parquet_page","text":"Named list. Many entries correspond columns result parquet_pages(). Additional entries : codec: compression codec. Possible values: has_repetition_levels: whether page repetition levels. has_definition_levels: whether page definition levels. schema_column: schema column page corresponds . Note leaf columns pages. data_type: low level Parquet data type. Possible values: repetition_type: whether column page belongs REQUIRED, OPTIONAL REPEATED. page_header: bytes page header raw vector. num_null: number missing (NA) values. set V2 data pages. num_rows: num_values flat tables, .e. files without repetition levels. compressed_data: data page raw vector. includes repetition definition levels, . data: uncompressed data, nanoparquet supports compression codec file (GZIP SNAPPY time writing), file compressed. latter case compressed_data.","code":""},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/read_parquet_page.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a page from a Parquet file — read_parquet_page","text":"","code":"file_name <- system.file(\"extdata/userdata1.parquet\", package = \"nanoparquet\") nanoparquet:::parquet_pages(file_name) #> # A data frame: 19 × 14 #>    file_name                 row_group column page_type page_header_offset #>    <chr>                         <int>  <int> <chr>                  <dbl> #>  1 /home/runner/work/_temp/…         0      0 DATA_PAGE                  4 #>  2 /home/runner/work/_temp/…         0      1 DATA_PAGE               6741 #>  3 /home/runner/work/_temp/…         0      2 DICTIONA…              10766 #>  4 /home/runner/work/_temp/…         0      2 DATA_PAGE              12259 #>  5 /home/runner/work/_temp/…         0      3 DICTIONA…              13334 #>  6 /home/runner/work/_temp/…         0      3 DATA_PAGE              15211 #>  7 /home/runner/work/_temp/…         0      4 DATA_PAGE              16239 #>  8 /home/runner/work/_temp/…         0      5 DICTIONA…              31726 #>  9 /home/runner/work/_temp/…         0      5 DATA_PAGE              31759 #> 10 /home/runner/work/_temp/…         0      6 DATA_PAGE              32031 #> 11 /home/runner/work/_temp/…         0      7 DATA_PAGE              42952 #> 12 /home/runner/work/_temp/…         0      8 DICTIONA…              53749 #> 13 /home/runner/work/_temp/…         0      8 DATA_PAGE              55009 #> 14 /home/runner/work/_temp/…         0      9 DATA_PAGE              55925 #> 15 /home/runner/work/_temp/…         0     10 DATA_PAGE              59312 #> 16 /home/runner/work/_temp/…         0     11 DICTIONA…              65063 #> 17 /home/runner/work/_temp/…         0     11 DATA_PAGE              67026 #> 18 /home/runner/work/_temp/…         0     12 DICTIONA…              68019 #> 19 /home/runner/work/_temp/…         0     12 DATA_PAGE              71089 #> # ℹ 9 more variables: uncompressed_page_size <int>, #> #   compressed_page_size <int>, crc <int>, num_values <int>, #> #   encoding <chr>, definition_level_encoding <chr>, #> #   repetition_level_encoding <chr>, data_offset <dbl>, #> #   page_header_length <int> options(max.print = 100)  # otherwise long raw vector nanoparquet:::read_parquet_page(file_name, 4L) #> $page_type #> [1] \"DATA_PAGE\" #>  #> $row_group #> [1] 0 #>  #> $column #> [1] 0 #>  #> $page_header_offset #> [1] 4 #>  #> $data_page_offset #> [1] 24 #>  #> $page_header_length #> [1] 20 #>  #> $compressed_page_size #> [1] 6717 #>  #> $uncompressed_page_size #> [1] 8000 #>  #> $codec #> [1] \"SNAPPY\" #>  #> $num_values #> [1] 1000 #>  #> $encoding #> [1] \"PLAIN\" #>  #> $definition_level_encoding #> [1] \"PLAIN\" #>  #> $repetition_level_encoding #> [1] \"PLAIN\" #>  #> $has_repetition_levels #> [1] FALSE #>  #> $has_definition_levels #> [1] FALSE #>  #> $schema_column #> [1] 1 #>  #> $data_type #> [1] \"INT64\" #>  #> $repetition_type #> [1] \"REQUIRED\" #>  #> $page_header #>  [1] 15 00 15 80 7d 15 fa 68 2c 15 d0 0f 15 00 15 00 15 00 00 00 #>  #> $data #>   [1] 40 be 0c f1 d8 2a 05 00 c0 86 e0 9a e0 2a 05 00 c0 28 33 45 d3 2a 05 #>  [24] 00 40 2b 96 ce d2 2a 05 00 c0 9c 33 91 d6 2a 05 00 80 a2 54 7b d8 2a #>  [47] 05 00 00 59 b2 77 d9 2a 05 00 80 ee 7d fc d7 2a 05 00 40 cf 71 8d d5 #>  [70] 2a 05 00 c0 bc 7b cd e1 2a 05 00 80 e4 da 72 d2 2a 05 00 80 30 4d 73 #>  [93] e1 2a 05 00 40 fe a4 0f #>  [ reached getOption(\"max.print\") -- omitted 7900 entries ] #>  #> $definition_levels_byte_length #> [1] NA #>  #> $repetition_levels_byte_length #> [1] NA #>  #> $num_nulls #> [1] NA #>  #> $num_rows #> [1] NA #>  #> $compressed_data #>   [1] c0 3e 30 40 be 0c f1 d8 2a 05 00 c0 86 e0 9a e0 01 08 2c 28 33 45 d3 #>  [24] 2a 05 00 40 2b 96 ce d2 01 10 28 9c 33 91 d6 2a 05 00 80 a2 54 7b 01 #>  [47] 28 10 00 59 b2 77 d9 01 10 0c ee 7d fc d7 01 28 0c cf 71 8d d5 01 28 #>  [70] 0c bc 7b cd e1 01 18 08 e4 da 72 01 38 0c 80 30 4d 73 01 10 30 40 fe #>  [93] a4 0f e2 2a 05 00 00 eb #>  [ reached getOption(\"max.print\") -- omitted 6617 entries ] #>"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/rle_decode_int.html","id":null,"dir":"Reference","previous_headings":"","what":"RLE decode integers — rle_decode_int","title":"RLE decode integers — rle_decode_int","text":"RLE decode integers","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/rle_decode_int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RLE decode integers — rle_decode_int","text":"","code":"rle_decode_int(   x,   bit_width = attr(x, \"bit_width\"),   length = attr(x, \"length\") %||% NA )"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/rle_decode_int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RLE decode integers — rle_decode_int","text":"x Raw vector encoded integers. bit_width Bit width used encoding. length Length output. NA assume x starts length output, encoded 4 byte integer.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/rle_decode_int.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"RLE decode integers — rle_decode_int","text":"decoded integer vector.","code":""},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/rle_encode_int.html","id":null,"dir":"Reference","previous_headings":"","what":"RLE encode integers — rle_encode_int","title":"RLE encode integers — rle_encode_int","text":"RLE encode integers","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/rle_encode_int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RLE encode integers — rle_encode_int","text":"","code":"rle_encode_int(x)"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/rle_encode_int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RLE encode integers — rle_encode_int","text":"x Integer vector.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/rle_encode_int.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"RLE encode integers — rle_encode_int","text":"Raw vector, encoded integers. two attributes: bit_length: number bits needed encode input, length: length original integer input.","code":""},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/write_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a data frame to a Parquet file — write_parquet","title":"Write a data frame to a Parquet file — write_parquet","text":"Writes contents R data frame Parquet file.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/write_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a data frame to a Parquet file — write_parquet","text":"","code":"write_parquet(   x,   file,   compression = c(\"snappy\", \"gzip\", \"zstd\", \"uncompressed\"),   metadata = NULL,   options = parquet_options() )"},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/write_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a data frame to a Parquet file — write_parquet","text":"x Data frame write. file Path output file. string \":raw:\", data frame written memory buffer, memory buffer returned raw vector. compression Compression algorithm use. Currently \"snappy\" (default), \"gzip\", \"zstd\", \"uncompressed\" supported. metadata Additional key-value metadata add file. must named character vector, data frame columns character columns called key value. options Nanoparquet options, see parquet_options().","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/write_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write a data frame to a Parquet file — write_parquet","text":"NULL, unless file \":raw:\", case Parquet file returned raw vector.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/write_parquet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write a data frame to a Parquet file — write_parquet","text":"write_parquet() converts string columns UTF-8 encoding calling base::enc2utf8(). factor levels.","code":""},{"path":[]},{"path":"https://r-lib.github.io/nanoparquet/dev/reference/write_parquet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a data frame to a Parquet file — write_parquet","text":"","code":"if (FALSE) { # add row names as a column, because `write_parquet()` ignores them. mtcars2 <- cbind(name = rownames(mtcars), mtcars) write_parquet(mtcars2, \"mtcars.parquet\") }"},{"path":"https://r-lib.github.io/nanoparquet/dev/news/index.html","id":"nanoparquet-development-version","dir":"Changelog","previous_headings":"","what":"nanoparquet (development version)","title":"nanoparquet (development version)","text":"write_parquet(file = \":raw:\") now works correctly larger data frames (#77). read_parquet() now reads DECIMAL values correctly INT32 INT64 columns scale zero.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/news/index.html","id":"nanoparquet-031","dir":"Changelog","previous_headings":"","what":"nanoparquet 0.3.1","title":"nanoparquet 0.3.1","text":"CRAN release: 2024-07-01 version fixes write_parquet() crash (#73).","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/news/index.html","id":"nanoparquet-030","dir":"Changelog","previous_headings":"","what":"nanoparquet 0.3.0","title":"nanoparquet 0.3.0","text":"CRAN release: 2024-06-17 read_parquet() type mapping changes: STRING logical type UTF8 converted type still read character vector, BYTE_ARRAY types without converted logical types , read list raw vectors. Missing values indicated NULL values. DECIMAL converted type read REALSXP now, even type FIXED_LEN_BYTE_ARRAY. (just BYTE_ARRAY). UUID logical type now read character vector, formatted 00112233-4455-6677-8899-aabbccddeeff. BYTE_ARRAY FIXED_LEN_BYTE_ARRAY types without logical converted types; unsupported ones: FLOAT16, INTERVAL; now read list raw vectors. Missing values denoted NULL. write_parquet() now automatically uses dictionary encoding columns many repeated values. first 10k rows used decide dictionary used . Similarly, logical columns written RLE encoding contain runs repeated values. NA values ignored selecting encoding (#18). write_parquet() can now write data frame memory buffer, returned raw vector, special \":raw:\" filename used (#31). read_parquet() can now read Parquet files V2 data pages (#37). read_parquet() write_parquet() now support GZIP ZSTD compressed Parquet files. read_parquet() now supports RLE encoding BOOLEAN columns also supports DELTA_BINARY_PACKED, DELTA_LENGTH_BYTE_ARRAY, DELTA_BYTE_ARRAY BYTE_STREAM_SPLIT encodings. parquet_columns() function now called parquet_column_types() can now map column types data frame Parquet types. parquet_info(), parquet_metadata() parquet_column_types() now work created_by metadata field unset. New parquet_options() function can use set nanoparquet options single read_parquet() write_parquet() call.","code":""},{"path":"https://r-lib.github.io/nanoparquet/dev/news/index.html","id":"nanoparquet-020","dir":"Changelog","previous_headings":"","what":"nanoparquet 0.2.0","title":"nanoparquet 0.2.0","text":"CRAN release: 2024-05-30 First release CRAN. contains Parquet reader https://github.com/hannes/miniparquet, Parquet writer, functions read Parquet metadata, many improvements.","code":""}]
